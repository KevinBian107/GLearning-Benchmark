{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Learning Data Exploration\n",
    "\n",
    "We will be looking at the **IMBD-BINARY** and the **MUTAG** graph dataset. Both are graph level classification tasks --> notice that this is a simple task doing binary classification, no graph structure or realtionship need to br predicted, just given a graph (node feature, edge connections, edge features) and its labels (target class), can we predict this class information.\n",
    "\n",
    "- **MUTAG**\n",
    "    - Task: Predict if a molecule is mutagenic or not\n",
    "    - Input: One graph = one molecule (each elements are the nodes, connection between them as edges)\n",
    "    - Output: One label per graph (0 or 1)\n",
    "\n",
    "- **IMDB-BINARY**\n",
    "    - Task: Predict if a movie is Action or Romance genre\n",
    "    - Input: One graph = one movie (actors as nodes, co-starring as edges)\n",
    "    - Output: One label per graph (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset, Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = TUDataset(root='./data', name='IMDB-BINARY')\n",
    "print(f\"IMDB-BINARY Dataset:\")\n",
    "print(f\"  Number of graphs: {len(imdb)}\")\n",
    "print(f\"  Number of classes: {imdb.num_classes}\")\n",
    "print(f\"  First graph - Nodes: {imdb[0].num_nodes}, Edges: {imdb[0].num_edges}\")\n",
    "\n",
    "mutag = TUDataset(root='./data', name='MUTAG')\n",
    "print(f\"MUTAG Dataset:\")\n",
    "print(f\"  Number of graphs: {len(mutag)}\")\n",
    "print(f\"  Number of classes: {mutag.num_classes}\")\n",
    "print(f\"  First graph - Nodes: {mutag[0].num_nodes}, Edges: {mutag[0].num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "for i in range(6):\n",
    "    G = to_networkx(imdb[i], to_undirected=True)\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, node_color='lightblue', node_size=200, \n",
    "            with_labels=False, ax=axes[i])\n",
    "    axes[i].set_title(f'IMDB Graph {i+1}\\nNodes: {imdb[i].num_nodes}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(15, 5))\n",
    "for i in range(6):\n",
    "    G = to_networkx(mutag[i], to_undirected=True)\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, node_color='lightgreen', node_size=400, \n",
    "            with_labels=True, ax=axes[i])\n",
    "    axes[i].set_title(f'MUTAG Graph {i+1}\\nClass: {mutag[i].y.item()}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to cytospace only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = mutag[0]\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "# atom_types = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
    "\n",
    "# for i in range(5):\n",
    "#     data = mutag[i]\n",
    "#     G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "#     # Add attributes\n",
    "#     for node_id, node_features in enumerate(data.x):\n",
    "#         atom_idx = torch.argmax(node_features).item()\n",
    "#         G.nodes[node_id]['atom_type'] = atom_types[atom_idx]\n",
    "#         G.nodes[node_id]['label'] = atom_types[atom_idx]\n",
    "    \n",
    "#     # Add graph-level attributes\n",
    "#     G.graph['class'] = data.y.item()\n",
    "#     G.graph['mutagenic'] = 'Yes' if data.y.item() == 1 else 'No'\n",
    "    \n",
    "#     filename = f\"out_graph/mutag_graph_{i}.graphml\"\n",
    "#     nx.write_graphml(G, filename)\n",
    "#     print(f\"✓ Exported {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_graph_sizes(dataset, name):\n",
    "    num_nodes = [g.num_nodes for g in dataset]\n",
    "    num_edges = [g.num_edges for g in dataset]\n",
    "    \n",
    "    print(f\"\\n{name} - Graph Size Statistics:\")\n",
    "    print(f\"  Nodes - Min: {min(num_nodes)}, Max: {max(num_nodes)}, Mean: {np.mean(num_nodes):.2f}, Std: {np.std(num_nodes):.2f}\")\n",
    "    print(f\"  Edges - Min: {min(num_edges)}, Max: {max(num_edges)}, Mean: {np.mean(num_edges):.2f}, Std: {np.std(num_edges):.2f}\")\n",
    "    \n",
    "    return num_nodes, num_edges\n",
    "\n",
    "imdb_nodes, imdb_edges = analyze_graph_sizes(imdb, \"IMDB-BINARY\")\n",
    "mutag_nodes, mutag_edges = analyze_graph_sizes(mutag, \"MUTAG\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].hist(imdb_nodes, bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('IMDB-BINARY: Node Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Number of Nodes')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(imdb_edges, bins=30, color='salmon', edgecolor='black')\n",
    "axes[0, 1].set_title('IMDB-BINARY: Edge Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Number of Edges')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 0].hist(mutag_nodes, bins=20, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('MUTAG: Node Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Number of Nodes')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(mutag_edges, bins=20, color='plum', edgecolor='black')\n",
    "axes[1, 1].set_title('MUTAG: Edge Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Number of Edges')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_degree_statistics(dataset, name):\n",
    "    all_degrees = []\n",
    "    for data in dataset:\n",
    "        G = to_networkx(data, to_undirected=True)\n",
    "        degrees = [deg for node, deg in G.degree()]\n",
    "        all_degrees.extend(degrees)\n",
    "    \n",
    "    print(f\"\\n{name} - Degree Statistics:\")\n",
    "    print(f\"  Average Degree: {np.mean(all_degrees):.2f}\")\n",
    "    print(f\"  Min Degree: {min(all_degrees)}\")\n",
    "    print(f\"  Max Degree: {max(all_degrees)}\")\n",
    "    print(f\"  Std Degree: {np.std(all_degrees):.2f}\")\n",
    "    \n",
    "    return all_degrees\n",
    "\n",
    "imdb_degrees = analyze_degree_statistics(imdb, \"IMDB-BINARY\")\n",
    "mutag_degrees = analyze_degree_statistics(mutag, \"MUTAG\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(imdb_degrees, bins=30, color='cornflowerblue', edgecolor='black')\n",
    "axes[0].set_title('IMDB-BINARY: Degree Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Node Degree')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1].hist(mutag_degrees, bins=20, color='mediumseagreen', edgecolor='black')\n",
    "axes[1].set_title('MUTAG: Degree Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Node Degree')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_types = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
    "print(f\"\\n   Atom types in MUTAG: {atom_types}\")\n",
    "print(f\"   (Features are one-hot encoded)\")\n",
    "\n",
    "atom_counts = {atom: 0 for atom in atom_types}\n",
    "\n",
    "for data in mutag:\n",
    "    for node_features in data.x:\n",
    "        atom_idx = torch.argmax(node_features).item()\n",
    "        if atom_idx < len(atom_types):\n",
    "            atom_counts[atom_types[atom_idx]] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(atom_counts.keys(), atom_counts.values(), color='skyblue', edgecolor='black')\n",
    "plt.title('MUTAG: Atom Type Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Atom Type')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_stats = []\n",
    "for i, data in enumerate(mutag[:10]):  # First 10 graphs\n",
    "    feature_sum = data.x.sum(dim=0)\n",
    "    atom_composition = [atom_types[j] for j in range(len(atom_types)) if feature_sum[j] > 0]\n",
    "    node_feature_stats.append({\n",
    "        'Graph': i,\n",
    "        'Num Nodes': data.num_nodes,\n",
    "        'Label': data.y.item(),\n",
    "        'Atoms Present': ', '.join(atom_composition)\n",
    "    })\n",
    "\n",
    "df_features = pd.DataFrame(node_feature_stats)\n",
    "print(\"\\n\" + df_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "mutag_labels = [data.y.item() for data in mutag]\n",
    "axes[0].hist(mutag_labels, bins=2, color='lightgreen', edgecolor='black', rwidth=0.8)\n",
    "axes[0].set_title('MUTAG: Class Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Class (0=Non-mutagenic, 1=Mutagenic)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "imdb_labels = [data.y.item() for data in imdb]\n",
    "axes[1].hist(imdb_labels, bins=2, color='lightcoral', edgecolor='black', rwidth=0.8)\n",
    "axes[1].set_title('IMDB-BINARY: Class Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Class (0=Action, 1=Romance)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Modeling Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "dataset = TUDataset(root='./data', name='MUTAG')\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = [dataset[i] for i in train_idx]\n",
    "test_dataset = [dataset[i] for i in test_idx]\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"Training graphs: {len(train_dataset)}\")\n",
    "print(f\"Test graphs: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # fully connected layer for classification\n",
    "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # global pooling (aggregate node features to graph-level)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SimpleGNN(\n",
    "    num_features=dataset.num_features,\n",
    "    hidden_dim=128,\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "print(\"Training started...\\n\")\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), desc=\"Training Progress\"):\n",
    "    loss, train_acc = train()\n",
    "    test_acc = test(test_loader)\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # if epoch % 10 == 0:\n",
    "    #     tqdm.write(f'Epoch {epoch:03d} | Loss: {loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(train_losses, color='blue', linewidth=2)\n",
    "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(train_accs, label='Train Accuracy', color='green', linewidth=2)\n",
    "axes[1].plot(test_accs, label='Test Accuracy', color='red', linewidth=2)\n",
    "axes[1].set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_acc = test(train_loader)\n",
    "final_test_acc = test(test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final Training Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.4f} ({final_test_acc*100:.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model.eval()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREDICTIONS ON TEST EXAMPLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        data = test_dataset[i]\n",
    "        data_batch = next(iter(DataLoader([data], batch_size=1)))\n",
    "        out = model(data_batch)\n",
    "        pred = out.argmax(dim=1).item()\n",
    "        true_label = data.y.item()\n",
    "        \n",
    "        print(f\"\\nGraph {i}:\")\n",
    "        print(f\"  Nodes: {data.num_nodes}, Edges: {data.num_edges}\")\n",
    "        print(f\"  True Label: {true_label} ({'Mutagenic' if true_label == 1 else 'Non-mutagenic'})\")\n",
    "        print(f\"  Predicted: {pred} ({'Mutagenic' if pred == 1 else 'Non-mutagenic'})\")\n",
    "        print(f\"  Correct: {'✓' if pred == true_label else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Learning for Multi-Class Node Classification\n",
    "\n",
    "We will be using **Cora**, a citation network dataset, to serve as an example:\n",
    "- Nodes: scientific publications (papers)\n",
    "- Edges: citation links between papers (if paper A cites paper B, there's an edge)\n",
    "- Node Features: 1,433-dimensional bag-of-words feature vectors (word presence/absence in each paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Loading Cora dataset...\")\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print(f\"Dataset: {dataset}\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Has isolated nodes: {data.has_isolated_nodes()}\")\n",
    "print(f\"Has self-loops: {data.has_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(\n",
    "    num_features=dataset.num_features,\n",
    "    hidden_channels=16,\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        \n",
    "        train_correct = pred[data.train_mask] == data.y[data.train_mask]\n",
    "        train_acc = int(train_correct.sum()) / int(data.train_mask.sum())\n",
    "        \n",
    "        val_correct = pred[data.val_mask] == data.y[data.val_mask]\n",
    "        val_acc = int(val_correct.sum()) / int(data.val_mask.sum())\n",
    "        \n",
    "        test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
    "        \n",
    "    return train_acc, val_acc, test_acc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining GCN model...\")\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in tqdm(range(1, 501), desc=\"Training\", unit=\"epoch\"):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc, _ = test()\n",
    "    train_losses.append(loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # if epoch % 20 == 0:\n",
    "    #     tqdm.write(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "    #                f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "train_acc, val_acc, test_acc, predictions = test()\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Results:\")\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(train_losses, color='blue', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Training Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(val_accuracies, color='green', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Validation Accuracy', fontsize=12)\n",
    "ax2.set_title('Validation Accuracy over Epochs', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edge_index = data.edge_index.numpy()\n",
    "G.add_edges_from(zip(edge_index[0], edge_index[1]))\n",
    "\n",
    "print(\"Computing Kamada-Kawai layout...\")\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "\n",
    "ax = axes[0]\n",
    "for class_id in range(dataset.num_classes):\n",
    "    mask = (data.y.numpy() == class_id)\n",
    "    nodes = np.where(mask)[0]\n",
    "    node_positions = np.array([pos[n] for n in nodes])\n",
    "    ax.scatter(node_positions[:, 0], node_positions[:, 1], \n",
    "              c=colors[class_id], label=f'Class {class_id}',\n",
    "              s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, ax=ax, alpha=0.1, width=0.5)\n",
    "\n",
    "ax.set_title('Cora Network - True Labels', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=10, framealpha=0.9)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1]\n",
    "predictions_np = predictions.numpy()\n",
    "for class_id in range(dataset.num_classes):\n",
    "    mask = (predictions_np == class_id)\n",
    "    nodes = np.where(mask)[0]\n",
    "    node_positions = np.array([pos[n] for n in nodes])\n",
    "    ax.scatter(node_positions[:, 0], node_positions[:, 1], \n",
    "              c=colors[class_id], label=f'Class {class_id}',\n",
    "              s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, ax=ax, alpha=0.1, width=0.5)\n",
    "\n",
    "ax.set_title(f'Cora Network - GCN Predictions\\n(Test Accuracy: {test_acc:.4f})', \n",
    "            fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=10, framealpha=0.9)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edge_index = data.edge_index.numpy()\n",
    "G.add_edges_from(zip(edge_index[0], edge_index[1]))\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "node_embeddings = data.x.numpy()\n",
    "pos_array = tsne.fit_transform(node_embeddings)\n",
    "pos = {i: pos_array[i] for i in range(len(pos_array))}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "ax = axes[0]\n",
    "for class_id in range(dataset.num_classes):\n",
    "    mask = (data.y.numpy() == class_id)\n",
    "    nodes = np.where(mask)[0]\n",
    "    node_positions = np.array([pos[n] for n in nodes])\n",
    "    ax.scatter(node_positions[:, 0], node_positions[:, 1], \n",
    "              c=colors[class_id], label=f'Class {class_id}',\n",
    "              s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Cora Network - True Labels', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=10, framealpha=0.9)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axes[1]\n",
    "predictions_np = predictions.numpy()\n",
    "for class_id in range(dataset.num_classes):\n",
    "    mask = (predictions_np == class_id)\n",
    "    nodes = np.where(mask)[0]\n",
    "    node_positions = np.array([pos[n] for n in nodes])\n",
    "    ax.scatter(node_positions[:, 0], node_positions[:, 1], \n",
    "              c=colors[class_id], label=f'Class {class_id}',\n",
    "              s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_title(f'Cora Network - GCN Predictions\\n(Test Accuracy: {test_acc:.4f})', \n",
    "            fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=10, framealpha=0.9)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "test_true = data.y[data.test_mask].numpy()\n",
    "test_pred = predictions[data.test_mask].numpy()\n",
    "\n",
    "cm = confusion_matrix(test_true, test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(dataset.num_classes),\n",
    "            yticklabels=range(dataset.num_classes),\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('True Class', fontsize=12)\n",
    "plt.title('Confusion Matrix (Test Set)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glearning_180a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
